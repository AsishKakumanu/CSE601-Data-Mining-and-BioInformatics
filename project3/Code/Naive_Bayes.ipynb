{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dataset : \n",
    "    project3_dataset1.txt, \n",
    "    project3_dataset2.txt\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T04:12:46.068098Z",
     "start_time": "2019-12-03T04:11:42.902784Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is text file different for Training and Test (y or n) : n\n",
      "Manual Input (yes, ignore if no) : yes\n",
      "Enter the File Name: project3_dataset4.txt\n",
      "Give the input seperated by comma:sunny,hot,high,weak\n",
      "Probability of 0: [0.79541735]\n",
      "Probability of 1: [0.20458265]\n",
      "Predicted Label: [0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "accuracy = precision = recall = fMeasure = 0\n",
    "\n",
    "# Function to read the Dataset file \n",
    "def folder(pathname):\n",
    "    path = os.getcwd()\n",
    "    file = path + pathname\n",
    "    df = pd.read_csv(file, delimiter=\"\\t\", header=None,index_col=False)\n",
    "    return df\n",
    "\n",
    "# Separating data & output labels\n",
    "def separate(df):\n",
    "    data = df_numpy[:,0:-1]\n",
    "    labels = df_numpy[:,-1].reshape((df_numpy.shape[0],1)).astype(int)\n",
    "    return data, labels\n",
    "\n",
    "# Splitting up the dataset into Training Dataset & Testing Dataset\n",
    "def split(test_ind,cross_valid_list):\n",
    "    test = cross_valid_list[test_ind]\n",
    "    train = np.vstack([x for i,x in enumerate(cross_valid_list) if i != test_ind])\n",
    "    return np.asarray(test),np.asarray(train)\n",
    "\n",
    "# Function to remove categorical data from the dataset\n",
    "def get_nonCat_data(data, indices):\n",
    "    return np.transpose(np.asarray([data[:,i] for i in range(len(data[0])) if i not in indices]))\n",
    "\n",
    "# Function to Square a numpy array\n",
    "def squared(prob):\n",
    "    return np.multiply(prob,prob)\n",
    "    \n",
    "# Function to calculate the Posterior Probability using mean and standard deviation.\n",
    "def posteriorProb(mean, stdv, test):\n",
    "    prob = test[:,0:-1] - mean\n",
    "    prob = -1 * squared(prob) / (2 * squared(stdv))\n",
    "    prob = np.array(prob,dtype =np.float32)\n",
    "    prob = np.exp(prob)\n",
    "    prob = prob/(math.sqrt(math.pi*2)*stdv)\n",
    "    prob = np.prod(prob, axis = 1)\n",
    "    return prob\n",
    "\n",
    "# Function to predict the class for test data using the probability.\n",
    "def predict(prob_one,prob_zero,test):\n",
    "    return [1 if prob_one[i] > prob_zero[i] else 0 for i in range(len(test))]\n",
    "  \n",
    "# Function to return false positives (m01), false negatives (m10), true positives (m11) and true negatives (m00)\n",
    "def metric(actual,predicted):\n",
    "    m11 = m00 = m10 = m01 = 0\n",
    "    for i in range(len(actual)):\n",
    "            if actual[i] == predicted[i]:\n",
    "                if actual[i] == 1: \n",
    "                    m11 = m11 + 1 #a\n",
    "                else:\n",
    "                    m00 = m00 + 1 #d\n",
    "            \n",
    "            else:\n",
    "                if actual[i] == 1: \n",
    "                    m10 = m10 + 1 #b\n",
    "                else:\n",
    "                    m01 = m01 + 1 #c\n",
    "    return m11, m10, m01, m00\n",
    "\n",
    "dataType = input(\"Is text file different for Training and Test (y or n) : \")\n",
    "\n",
    "if dataType == 'n':\n",
    "    inp = input(\"Manual Input (yes, ignore if no) : \")\n",
    "    if any(inp):\n",
    "        file = input(\"Enter the File Name: \")\n",
    "        df = folder(str('/'+ file))\n",
    "        df_numpy = df.to_numpy()\n",
    "        df_numpy_clone = np.copy(df_numpy)\n",
    "\n",
    "        # Checking for String data and changing them to Numerical data\n",
    "        Strings = []\n",
    "        for i in range(len(df_numpy[0])):\n",
    "            if isinstance(df_numpy[0][i],str):\n",
    "                Strings.append(i)\n",
    "        for i in Strings:\n",
    "            unique_classes = np.unique(df_numpy[:,i])\n",
    "            repl_vals = list(range(len(unique_classes)))\n",
    "            dictionary = dict(zip(unique_classes,repl_vals))\n",
    "            for j in range(len(df_numpy[:,i])):\n",
    "                df_numpy[j][i] = dictionary.get(df_numpy[j][i])\n",
    "\n",
    "        inp =input(\"Give the input seperated by comma:\")\n",
    "        values=[i for i in inp.split(',')]\n",
    "        testdata=list(values)\n",
    "\n",
    "        testdata=np.array(testdata).astype('object')\n",
    "        testdata=np.reshape(testdata,(1,4))\n",
    "        #print(testdata)\n",
    "\n",
    "        for i in Strings:\n",
    "            unique_classes = np.unique(df_numpy_clone[:,i])\n",
    "            repl_vals = list(range(len(unique_classes)))\n",
    "            dictionary = dict(zip(unique_classes,repl_vals))\n",
    "            #print(dictionary)\n",
    "            for j in range(len(testdata[:,i])):\n",
    "                testdata[j][i] = dictionary.get(testdata[j][i])\n",
    "\n",
    "\n",
    "        # Function to return test and train splits\n",
    "        test,train = testdata,df_numpy\n",
    "        zero_class = []\n",
    "        one_class = []\n",
    "\n",
    "        # Adding different class labels to different arrays\n",
    "        for j in range(len(train)):\n",
    "            if int(train[j,-1])==1:\n",
    "                one_class.append(train[j,:])\n",
    "            else:\n",
    "                zero_class.append(train[j,:])\n",
    "\n",
    "        # Changing the type of both arrays to numpy array\n",
    "        zero_class = np.asarray(zero_class)\n",
    "        one_class = np.asarray(one_class)\n",
    "\n",
    "\n",
    "        # Execute the code if there are atleast one categorical feature in the dataset\n",
    "        # Calculating the prior probabilities of both class labels zero and one. \n",
    "        if len(Strings) != 0:\n",
    "            string_prior_zero = {}\n",
    "            string_prior_one = {}\n",
    "            for j in Strings:\n",
    "                string_prior_zero[j] = {}\n",
    "                string_prior_one[j] = {}\n",
    "                for k in np.unique(train[:,j]):\n",
    "                    zero_count = list(zero_class[:,-1].astype(int)).count(0)\n",
    "                    one_count = list(one_class[:,-1].astype(int)).count(1)                \n",
    "                    prior_zero = float(list(zero_class[:,j]).count(k))/zero_count\n",
    "                    prior_one = float(list(one_class[:,j]).count(k))/one_count\n",
    "                    string_prior_zero[j][k] = prior_zero\n",
    "                    string_prior_one[j][k] = prior_one\n",
    "\n",
    "        # Calculating prior probabilities of different classes\n",
    "        prior_prob_zero = float(list(train[:,-1]).count(0))/len(train)\n",
    "        prior_prob_one = float(list(train[:,-1]).count(1))/len(train)\n",
    "\n",
    "        #Calculating probability for categorical explicitly and adding probabilities to in the numpy array at their respective indices\n",
    "        string_prob_zero = np.empty(test.shape[0])\n",
    "        string_prob_one = np.empty(test.shape[0])\n",
    "        string_prob_one.fill(1.0)\n",
    "        string_prob_zero.fill(1.0)\n",
    "        if len(Strings) != 0:\n",
    "            for t in range(len(test)):\n",
    "                for i in Strings:\n",
    "                    string_prob_one[t] *= string_prior_one[i][test[t][i]]\n",
    "                    string_prob_zero[t] *= string_prior_zero[i][test[t][i]]\n",
    "\n",
    "        # Get test data without categorical data\n",
    "        test_ = get_nonCat_data(test, Strings)\n",
    "\n",
    "        s = (prior_prob_one * string_prob_one) + (prior_prob_zero * string_prob_zero)\n",
    "\n",
    "        # Calculating Posterior probabilities using respective means, std_deviation for test dataset \n",
    "        prob_zero = (prior_prob_zero * string_prob_zero)/s\n",
    "        prob_one = (prior_prob_one * string_prob_one)/s\n",
    "\n",
    "        print('Probability of 0: {}'.format(prob_zero))\n",
    "        print('Probability of 1: {}'.format(prob_one))\n",
    "        # predict the class of each data row in the test dataset\n",
    "        predicted = predict(prob_one,prob_zero,test)\n",
    "        print(\"Predicted Label: {}\".format(predicted))\n",
    "\n",
    "    else:\n",
    "        file = input(\"Enter the File Name: \")\n",
    "        df = folder(str('/'+ file))\n",
    "        df_numpy = df.to_numpy()\n",
    "        # Checking for String data and changing them to Numerical data\n",
    "        Strings = []\n",
    "        for i in range(len(df_numpy[0])):\n",
    "            if isinstance(df_numpy[0][i],str):\n",
    "                Strings.append(i)\n",
    "        for i in Strings:\n",
    "            unique_classes = np.unique(df_numpy[:,i])\n",
    "            repl_vals = list(range(len(unique_classes)))\n",
    "            dictionary = dict(zip(unique_classes,repl_vals))\n",
    "            for j in range(len(df_numpy[:,i])):\n",
    "                df_numpy[j][i] = dictionary.get(df_numpy[j][i])\n",
    "\n",
    "\n",
    "        # No. of K-Folds\n",
    "        folds = int(input(\"Enter the Number of folds (less than {}): \".format(df_numpy.shape[0])))\n",
    "        if folds:\n",
    "            crossSplits = np.array_split(df_numpy,folds)\n",
    "        else:\n",
    "            crossSplits = np.array_split(df_numpy,df_numpy.shape[0]-1)\n",
    "\n",
    "\n",
    "        # Cross validating k-times \n",
    "        for i in range(len(crossSplits)):\n",
    "\n",
    "            # Function to return test and train splits\n",
    "            test,train = split(i,crossSplits)\n",
    "            zero_class = []\n",
    "            one_class = []\n",
    "\n",
    "            # Adding different class labels to different arrays\n",
    "            for j in range(len(train)):\n",
    "                if int(train[j,-1])==1:\n",
    "                    one_class.append(train[j,:])\n",
    "                else:\n",
    "                    zero_class.append(train[j,:])\n",
    "\n",
    "            # Changing the type of both arrays to numpy array\n",
    "            zero_class = np.asarray(zero_class)\n",
    "            one_class = np.asarray(one_class)\n",
    "\n",
    "            # Execute the code if there are atleast one categorical feature in the dataset\n",
    "            # Calculating the prior probabilities of both class labels zero and one. \n",
    "            if len(Strings) != 0:\n",
    "                string_prior_zero = {}\n",
    "                string_prior_one = {}\n",
    "                for j in Strings:\n",
    "                    string_prior_zero[j] = {}\n",
    "                    string_prior_one[j] = {}\n",
    "                    for k in np.unique(train[:,j]):\n",
    "                        zero_count = list(zero_class[:,-1].astype(int)).count(0)\n",
    "                        one_count = list(one_class[:,-1].astype(int)).count(1)                \n",
    "                        prior_zero = float(list(zero_class[:,j]).count(k))/zero_count\n",
    "                        prior_one = float(list(one_class[:,j]).count(k))/one_count\n",
    "                        string_prior_zero[j][k] = prior_zero\n",
    "                        string_prior_one[j][k] = prior_one\n",
    "\n",
    "            # Calculating prior probabilities of different classes\n",
    "            prior_prob_zero = float(list(train[:,-1]).count(0))/len(train)\n",
    "            prior_prob_one = float(list(train[:,-1]).count(1))/len(train)\n",
    "\n",
    "            # Excluding the categorical data as we calculated priors for those already.\n",
    "            train_ = get_nonCat_data(train,Strings)\n",
    "            zero = [row[0:-1] for row in train_ if row[-1] == 0]\n",
    "            one = [row[0:-1] for row in train_ if row[-1] == 1]\n",
    "            zero = np.array(zero).astype(np.float64)\n",
    "            one = np.array(one).astype(np.float64)\n",
    "            mean_zero = np.mean(zero,axis=0)\n",
    "            mean_one = np.mean(one,axis=0)\n",
    "            std_zero = np.std(zero,axis=0)\n",
    "            std_one = np.std(one,axis=0)\n",
    "\n",
    "            #Calculating probability for categorical explicitly and adding probabilities to in the numpy array at their respective indices\n",
    "            string_prob_zero = np.empty(test.shape[0])\n",
    "            string_prob_one = np.empty(test.shape[0])\n",
    "            string_prob_one.fill(1.0)\n",
    "            string_prob_zero.fill(1.0)\n",
    "            if len(Strings) != 0:\n",
    "                for t in range(len(test)):\n",
    "                    for i in Strings:\n",
    "                        string_prob_one[t] *= string_prior_one[i][test[t][i]]\n",
    "                        string_prob_zero[t] *= string_prior_zero[i][test[t][i]]\n",
    "\n",
    "            # Get test data without categorical data\n",
    "            test_ = get_nonCat_data(test, Strings)\n",
    "\n",
    "            # Calculating Posterior probabilities using respective means, std_deviation for test dataset \n",
    "            prob_zero = prior_prob_zero * np.multiply(posteriorProb(mean_zero,std_zero,test_),string_prob_zero)\n",
    "            prob_one = prior_prob_one * np.multiply(posteriorProb(mean_one,std_one,test_),string_prob_one)\n",
    "\n",
    "            # predict the class of each data row in the test dataset\n",
    "            predicted = predict(prob_one,prob_zero,test)\n",
    "\n",
    "            # Metrics\n",
    "            m11, m10, m01, m00 = metric(test[:,-1],np.asarray(predicted))\n",
    "            accuracy += float(m11 + m00)/(m11 + m10 + m01 + m00) if (m11 + m10 + m01 + m00) else 0\n",
    "            precision += float(m11)/(m11 + m01) if (m11 + m01) else 0\n",
    "            fMeasure += float(2*m11)/((2*m11) + m10 + m01) if ((2*m11) + m10 + m01) else 0\n",
    "            recall += float(m11)/(m11+m10) if (m11+m10) else 0\n",
    "\n",
    "elif dataType == 'y':\n",
    "    train_data_file = input(\"Enter the Training Data File Name: \")\n",
    "    df_train = folder(str('/'+ train_data_file))\n",
    "    df_numpy_train = df_train.to_numpy()\n",
    "    \n",
    "    test_data_file = input('Enter the Testing Data File Name: ')\n",
    "    df_test = folder(str('/'+ test_data_file))\n",
    "    df_numpy_test = df_test.to_numpy()\n",
    "    \n",
    "    Strings = []\n",
    "    for i in range(len(df_numpy[0])):\n",
    "        if isinstance(df_numpy[0][i],str):\n",
    "            Strings.append(i)\n",
    "    for i in Strings:\n",
    "        unique_classes = np.unique(df_numpy[:,i])\n",
    "        repl_vals = list(range(len(unique_classes)))\n",
    "        dictionary = dict(zip(unique_classes,repl_vals))\n",
    "        for j in range(len(df_numpy[:,i])):\n",
    "            df_numpy[j][i] = dictionary.get(df_numpy[j][i])\n",
    "            \n",
    "    test,train = df_numpy_test,df_numpy_train\n",
    "    zero_class = []\n",
    "    one_class = []\n",
    "\n",
    "    # Adding different class labels to different arrays\n",
    "    for j in range(len(train)):\n",
    "        if int(train[j,-1])==1:\n",
    "            one_class.append(train[j,:])\n",
    "        else:\n",
    "            zero_class.append(train[j,:])\n",
    "\n",
    "    # Changing the type of both arrays to numpy array\n",
    "    zero_class = np.asarray(zero_class)\n",
    "    one_class = np.asarray(one_class)\n",
    "\n",
    "    # Execute the code if there are atleast one categorical feature in the dataset\n",
    "    # Calculating the prior probabilities of both class labels zero and one. \n",
    "    if len(Strings) != 0:\n",
    "        string_prior_zero = {}\n",
    "        string_prior_one = {}\n",
    "        for j in Strings:\n",
    "            string_prior_zero[j] = {}\n",
    "            string_prior_one[j] = {}\n",
    "            for k in np.unique(train[:,j]):\n",
    "                zero_count = list(zero_class[:,-1].astype(int)).count(0)\n",
    "                one_count = list(one_class[:,-1].astype(int)).count(1)                \n",
    "                prior_zero = float(list(zero_class[:,j]).count(k))/zero_count\n",
    "                prior_one = float(list(one_class[:,j]).count(k))/one_count\n",
    "                string_prior_zero[j][k] = prior_zero\n",
    "                string_prior_one[j][k] = prior_one\n",
    "\n",
    "    # Calculating prior probabilities of different classes\n",
    "    prior_prob_zero = float(list(train[:,-1]).count(0))/len(train)\n",
    "    prior_prob_one = float(list(train[:,-1]).count(1))/len(train)\n",
    "\n",
    "    # Excluding the categorical data as we calculated priors for those already.\n",
    "    train_ = get_nonCat_data(train,Strings)\n",
    "    zero = [row[0:-1] for row in train_ if row[-1] == 0]\n",
    "    one = [row[0:-1] for row in train_ if row[-1] == 1]\n",
    "    zero = np.array(zero).astype(np.float64)\n",
    "    one = np.array(one).astype(np.float64)\n",
    "    mean_zero = np.mean(zero,axis=0)\n",
    "    mean_one = np.mean(one,axis=0)\n",
    "    std_zero = np.std(zero,axis=0)\n",
    "    std_one = np.std(one,axis=0)\n",
    "\n",
    "    #Calculating probability for categorical explicitly and adding probabilities to in the numpy array at their respective indices\n",
    "    string_prob_zero = np.empty(test.shape[0])\n",
    "    string_prob_one = np.empty(test.shape[0])\n",
    "    string_prob_one.fill(1.0)\n",
    "    string_prob_zero.fill(1.0)\n",
    "    if len(Strings) != 0:\n",
    "        for t in range(len(test)):\n",
    "            for i in Strings:\n",
    "                string_prob_one[t] *= string_prior_one[i][test[t][i]]\n",
    "                string_prob_zero[t] *= string_prior_zero[i][test[t][i]]\n",
    "\n",
    "    # Get test data without categorical data\n",
    "    test_ = get_nonCat_data(test, Strings)\n",
    "\n",
    "    # Calculating Posterior probabilities using respective means, std_deviation for test dataset \n",
    "    prob_zero = prior_prob_zero * np.multiply(posteriorProb(mean_zero,std_zero,test_),string_prob_zero)\n",
    "    prob_one = prior_prob_one * np.multiply(posteriorProb(mean_one,std_one,test_),string_prob_one)\n",
    "\n",
    "    # predict the class of each data row in the test dataset\n",
    "    predicted = predict(prob_one,prob_zero,test)\n",
    "\n",
    "    # Metrics\n",
    "    m11, m10, m01, m00 = metric(test[:,-1],np.asarray(predicted))\n",
    "    accuracy += float(m11 + m00)/(m11 + m10 + m01 + m00) if (m11 + m10 + m01 + m00) else 0\n",
    "    precision += float(m11)/(m11 + m01) if (m11 + m01) else 0\n",
    "    fMeasure += float(2*m11)/((2*m11) + m10 + m01) if ((2*m11) + m10 + m01) else 0\n",
    "    recall += float(m11)/(m11+m10) if (m11+m10) else 0\n",
    "    \n",
    "    print(\"Accuracy : {}\".format(accuracy*100))\n",
    "    print(\"Precision : {}\".format(precision*100))\n",
    "    print(\"Recall : {}\".format(recall*100))\n",
    "    print(\"F1 - Measure : {}\".format(fMeasure*100))\n",
    "\n",
    "if dataType == 'n' and not any(inp):\n",
    "    print(\"Accuracy : {}\".format(accuracy*10))\n",
    "    print(\"Precision : {}\".format(precision*10))\n",
    "    print(\"Recall : {}\".format(recall*10))\n",
    "    print(\"F1 - Measure : {}\".format(fMeasure*10))\n",
    "    \n",
    "    print('\\n')\n",
    "    print('After Normalizing (only when fold value is high)')\n",
    "    print(\"Accuracy : {}\".format(accuracy/folds*100)) \n",
    "    print(\"Precision : {}\".format(precision/folds*100))\n",
    "    print(\"Recall : {}\".format(recall/folds*100))\n",
    "    print(\"F1 - Measure : {}\".format(fMeasure/folds*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
